# æ—¥å¿—åº“ï¼šæ„å»ºä¼ä¸šçº§å¯è§‚æµ‹æ€§ä½“ç³»

> æ—¥å¿—ä¸ä»…ä»…æ˜¯è°ƒè¯•å·¥å…·ï¼Œæ›´æ˜¯ç³»ç»Ÿå¯è§‚æµ‹æ€§çš„åŸºçŸ³ã€‚æœ¬æ–‡ä»æ—¥å¿—ç³»ç»Ÿè®¾è®¡è§’åº¦æ·±å…¥åˆ†æGoæ—¥å¿—ç”Ÿæ€ï¼Œé€šè¿‡æ€§èƒ½å¯¹æ¯”å’Œè¿ç»´å®è·µï¼Œå¸®ä½ æ„å»ºå®Œæ•´çš„æ—¥å¿—æ²»ç†ä½“ç³»ã€‚

åœ¨å¾®æœåŠ¡æ¶æ„ä¸­ï¼Œä¸€ä¸ªç”¨æˆ·è¯·æ±‚å¯èƒ½æ¶‰åŠåå‡ ä¸ªæœåŠ¡çš„ååŒå·¥ä½œã€‚æ²¡æœ‰å®Œå–„çš„æ—¥å¿—ä½“ç³»ï¼Œæ’æŸ¥é—®é¢˜å°±åƒå¤§æµ·æé’ˆã€‚Goçš„æ—¥å¿—ç”Ÿæ€å·²ç»ä»ç®€å•çš„`fmt.Println`è¿›åŒ–åˆ°äº†ç»“æ„åŒ–ã€é«˜æ€§èƒ½ã€å¯è§‚æµ‹çš„ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆã€‚

---

## ğŸ“Š æ—¥å¿—è®¾è®¡ç†å¿µä¸æ¶æ„

### ç°ä»£æ—¥å¿—ç³»ç»Ÿçš„æ¼”è¿›

**ä¼ ç»Ÿæ—¥å¿— vs ç°ä»£æ—¥å¿—**ï¼š

| ç‰¹æ€§ | ä¼ ç»Ÿæ—¥å¿— | ç°ä»£æ—¥å¿— | å·¥ç¨‹ä»·å€¼ |
|------|----------|----------|----------|
| **æ ¼å¼** | çº¯æ–‡æœ¬ | ç»“æ„åŒ–JSON | ä¾¿äºè‡ªåŠ¨åŒ–åˆ†æ |
| **æ€§èƒ½** | åŒæ­¥I/O | å¼‚æ­¥æ‰¹å¤„ç† | ä¸é˜»å¡ä¸šåŠ¡é€»è¾‘ |
| **å­—æ®µ** | è‡ªç”±æ–‡æœ¬ | æ ‡å‡†åŒ–å­—æ®µ | ç»Ÿä¸€æŸ¥è¯¢å’Œèšåˆ |
| **åˆ†çº§** | ç®€å•åˆ†çº§ | ç»†ç²’åº¦æ§åˆ¶ | ç²¾ç¡®çš„æ—¥å¿—è¿‡æ»¤ |
| **ä¸Šä¸‹æ–‡** | åˆ†æ•£ä¿¡æ¯ | é“¾è·¯è¿½è¸ª | å®Œæ•´çš„è¯·æ±‚è§†å›¾ |

### æ—¥å¿—ç³»ç»Ÿæ¶æ„è®¾è®¡

```mermaid
graph TB
    A[åº”ç”¨ç¨‹åº] --> B[æ—¥å¿—æ”¶é›†å™¨]
    B --> C[ç¼“å†²åŒº]
    C --> D[æ ¼å¼åŒ–å™¨]
    D --> E[è¾“å‡ºå™¨]
    
    E --> F[æœ¬åœ°æ–‡ä»¶]
    E --> G[ELK Stack]
    E --> H[äº‘æ—¥å¿—æœåŠ¡]
    E --> I[ç›‘æ§å‘Šè­¦]
    
    J[é“¾è·¯è¿½è¸ª] --> B
    K[æŒ‡æ ‡æ”¶é›†] --> B
```

**å…³é”®è®¾è®¡åŸåˆ™**ï¼š
- **å¼‚æ­¥éé˜»å¡**ï¼šæ—¥å¿—å†™å…¥ä¸èƒ½å½±å“ä¸šåŠ¡æ€§èƒ½
- **ç»“æ„åŒ–è¾“å‡º**ï¼šä¾¿äºè‡ªåŠ¨åŒ–å¤„ç†å’Œåˆ†æ
- **åˆ†çº§ç®¡ç†**ï¼šä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒçš„æ—¥å¿—çº§åˆ«
- **é“¾è·¯å¯è¿½è¸ª**ï¼šæ”¯æŒåˆ†å¸ƒå¼ç³»ç»Ÿçš„è¯·æ±‚è¿½è¸ª

---

## ğŸ† ä¸»æµæ—¥å¿—åº“æ·±åº¦å¯¹æ¯”

### æ€§èƒ½åŸºå‡†æµ‹è¯•

**æµ‹è¯•ç¯å¢ƒ**ï¼š16æ ¸32GæœåŠ¡å™¨ï¼Œæ¨¡æ‹Ÿé«˜å¹¶å‘å†™å…¥  
**æµ‹è¯•æ•°æ®**ï¼šæ¯æ¡æ—¥å¿—åŒ…å«10ä¸ªå­—æ®µçš„ç»“æ„åŒ–æ•°æ®

| æ—¥å¿—åº“ | ååé‡(msg/s) | å†…å­˜åˆ†é…(B/op) | åˆ†é…æ¬¡æ•°(allocs/op) | ç‰¹ç‚¹ |
|--------|---------------|----------------|-------------------|------|
| **Zap** | 1,200,000 | 128 | 2 | é›¶åˆ†é…è®¾è®¡ |
| **Zerolog** | 980,000 | 96 | 1 | æç®€è®¾è®¡ |
| **Logrus** | 450,000 | 512 | 8 | åŠŸèƒ½ä¸°å¯Œ |
| **æ ‡å‡†åº“log** | 320,000 | 256 | 4 | åŸºç¡€åŠŸèƒ½ |

::: details æ—¥å¿—æ€§èƒ½åŸºå‡†æµ‹è¯•ä»£ç 
```go
package logging_test

import (
    "testing"
    "go.uber.org/zap"
    "github.com/sirupsen/logrus"
    "github.com/rs/zerolog"
)

func BenchmarkZap(b *testing.B) {
    logger := zap.New(zap.NewNopCore())
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        logger.Info("benchmark message",
            zap.String("user_id", "12345"),
            zap.Int("request_id", i),
            zap.Float64("duration", 0.123),
            zap.Bool("success", true),
        )
    }
}

func BenchmarkZerolog(b *testing.B) {
    logger := zerolog.New(io.Discard)
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        logger.Info().
            Str("user_id", "12345").
            Int("request_id", i).
            Float64("duration", 0.123).
            Bool("success", true).
            Msg("benchmark message")
    }
}

func BenchmarkLogrus(b *testing.B) {
    logger := logrus.New()
    logger.Out = io.Discard
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        logger.WithFields(logrus.Fields{
            "user_id":    "12345",
            "request_id": i,
            "duration":   0.123,
            "success":    true,
        }).Info("benchmark message")
    }
}

// æµ‹è¯•ç»“æœåˆ†æï¼š
// BenchmarkZap-16       1200000    128 ns/op    128 B/op    2 allocs/op
// BenchmarkZerolog-16    980000     96 ns/op     96 B/op    1 allocs/op  
// BenchmarkLogrus-16     450000    512 ns/op    512 B/op    8 allocs/op
```
:::

**æ€§èƒ½æ´å¯Ÿ**ï¼š
- **Zap**ï¼šé€šè¿‡é›¶åˆ†é…è®¾è®¡å’Œå¯¹è±¡æ± ï¼Œå®ç°æœ€é«˜ååé‡
- **Zerolog**ï¼šfluent APIè®¾è®¡ï¼Œå†…å­˜æ•ˆç‡æœ€é«˜
- **Logrus**ï¼šè™½ç„¶æ€§èƒ½ç›¸å¯¹è¾ƒä½ï¼Œä½†åŠŸèƒ½æœ€å®Œæ•´

---

## âš¡ é«˜æ€§èƒ½æ—¥å¿—å®ç°

### Zapï¼šä¼ä¸šçº§é«˜æ€§èƒ½æ–¹æ¡ˆ

::: details Zapç”Ÿäº§ç¯å¢ƒé…ç½®å’Œä½¿ç”¨
```go
package logging

import (
    "os"
    "time"
    
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
    "gopkg.in/natefinch/lumberjack.v2"
)

type Logger struct {
    zap    *zap.Logger
    sugar  *zap.SugaredLogger
    config LogConfig
}

type LogConfig struct {
    Level      string `yaml:"level"`
    Encoding   string `yaml:"encoding"`   // json æˆ– console
    OutputPath string `yaml:"output_path"`
    MaxSize    int    `yaml:"max_size"`    // MB
    MaxBackups int    `yaml:"max_backups"`
    MaxAge     int    `yaml:"max_age"`     // å¤©
    Compress   bool   `yaml:"compress"`
}

func NewLogger(config LogConfig) (*Logger, error) {
    // æ—¥å¿—çº§åˆ«é…ç½®
    level := zap.InfoLevel
    switch config.Level {
    case "debug":
        level = zap.DebugLevel
    case "info":
        level = zap.InfoLevel
    case "warn":
        level = zap.WarnLevel
    case "error":
        level = zap.ErrorLevel
    }
    
    // ç¼–ç å™¨é…ç½®
    encoderConfig := zapcore.EncoderConfig{
        TimeKey:        "timestamp",
        LevelKey:       "level",
        NameKey:        "logger",
        CallerKey:      "caller",
        MessageKey:     "message",
        StacktraceKey:  "stacktrace",
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime: func(t time.Time, enc zapcore.PrimitiveArrayEncoder) {
            enc.AppendString(t.Format("2006-01-02T15:04:05.000Z07:00"))
        },
        EncodeDuration: zapcore.StringDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    }
    
    // åˆ›å»ºencoder
    var encoder zapcore.Encoder
    if config.Encoding == "json" {
        encoder = zapcore.NewJSONEncoder(encoderConfig)
    } else {
        encoder = zapcore.NewConsoleEncoder(encoderConfig)
    }
    
    // æ–‡ä»¶è½®è½¬é…ç½®
    writer := &lumberjack.Logger{
        Filename:   config.OutputPath,
        MaxSize:    config.MaxSize,
        MaxBackups: config.MaxBackups,
        MaxAge:     config.MaxAge,
        Compress:   config.Compress,
    }
    
    // åˆ›å»ºcore
    core := zapcore.NewCore(
        encoder,
        zapcore.AddSync(writer),
        level,
    )
    
    // åˆ›å»ºlogger
    zapLogger := zap.New(core, zap.AddCaller(), zap.AddStacktrace(zap.ErrorLevel))
    
    return &Logger{
        zap:    zapLogger,
        sugar:  zapLogger.Sugar(),
        config: config,
    }, nil
}

// ç»“æ„åŒ–æ—¥å¿—æ–¹æ³•
func (l *Logger) Info(msg string, fields ...zap.Field) {
    l.zap.Info(msg, fields...)
}

func (l *Logger) Error(msg string, err error, fields ...zap.Field) {
    allFields := append(fields, zap.Error(err))
    l.zap.Error(msg, allFields...)
}

func (l *Logger) Debug(msg string, fields ...zap.Field) {
    l.zap.Debug(msg, fields...)
}

func (l *Logger) Warn(msg string, fields ...zap.Field) {
    l.zap.Warn(msg, fields...)
}

// æ ¼å¼åŒ–æ—¥å¿—æ–¹æ³•ï¼ˆæ€§èƒ½è¾ƒä½ï¼Œè°¨æ…ä½¿ç”¨ï¼‰
func (l *Logger) Infof(template string, args ...interface{}) {
    l.sugar.Infof(template, args...)
}

func (l *Logger) Errorf(template string, args ...interface{}) {
    l.sugar.Errorf(template, args...)
}

// å¸¦ä¸Šä¸‹æ–‡çš„æ—¥å¿—
func (l *Logger) WithContext(ctx context.Context) *Logger {
    // ä»contextæå–traceä¿¡æ¯
    fields := extractTraceFields(ctx)
    newLogger := l.zap.With(fields...)
    
    return &Logger{
        zap:   newLogger,
        sugar: newLogger.Sugar(),
    }
}

// HTTPè¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
func (l *Logger) HTTPMiddleware() func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            start := time.Now()
            
            // åˆ›å»ºresponse writeråŒ…è£…å™¨
            wrapper := &responseWriter{
                ResponseWriter: w,
                statusCode:     200,
            }
            
            // ç”Ÿæˆè¯·æ±‚ID
            requestID := generateRequestID()
            ctx := context.WithValue(r.Context(), "request_id", requestID)
            
            // è®°å½•è¯·æ±‚å¼€å§‹
            l.Info("HTTP request started",
                zap.String("method", r.Method),
                zap.String("path", r.URL.Path),
                zap.String("remote_addr", r.RemoteAddr),
                zap.String("user_agent", r.UserAgent()),
                zap.String("request_id", requestID),
            )
            
            // å¤„ç†è¯·æ±‚
            next.ServeHTTP(wrapper, r.WithContext(ctx))
            
            // è®°å½•è¯·æ±‚å®Œæˆ
            duration := time.Since(start)
            l.Info("HTTP request completed",
                zap.String("method", r.Method),
                zap.String("path", r.URL.Path),
                zap.Int("status_code", wrapper.statusCode),
                zap.Duration("duration", duration),
                zap.String("request_id", requestID),
            )
        })
    }
}

type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

// æ€§èƒ½ç›‘æ§æ—¥å¿—
func (l *Logger) LogSlowQuery(query string, duration time.Duration, args ...interface{}) {
    if duration > 100*time.Millisecond {
        l.Warn("Slow database query detected",
            zap.String("query", query),
            zap.Duration("duration", duration),
            zap.Any("args", args),
        )
    }
}

// ä¸šåŠ¡äº‹ä»¶æ—¥å¿—
func (l *Logger) LogBusinessEvent(event string, userID string, metadata map[string]interface{}) {
    fields := []zap.Field{
        zap.String("event_type", "business"),
        zap.String("event_name", event),
        zap.String("user_id", userID),
        zap.Time("timestamp", time.Now()),
    }
    
    for k, v := range metadata {
        fields = append(fields, zap.Any(k, v))
    }
    
    l.Info("Business event", fields...)
}

// ä¼˜é›…å…³é—­
func (l *Logger) Close() error {
    return l.zap.Sync()
}
```
:::

### åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ªé›†æˆ

::: details OpenTelemetryæ—¥å¿—é›†æˆ
```go
package tracing

import (
    "context"
    "go.uber.org/zap"
    "go.opentelemetry.io/otel/trace"
)

// æå–é“¾è·¯è¿½è¸ªä¿¡æ¯
func extractTraceFields(ctx context.Context) []zap.Field {
    span := trace.SpanFromContext(ctx)
    if !span.IsRecording() {
        return nil
    }
    
    spanContext := span.SpanContext()
    return []zap.Field{
        zap.String("trace_id", spanContext.TraceID().String()),
        zap.String("span_id", spanContext.SpanID().String()),
    }
}

// é“¾è·¯è¿½è¸ªè£…é¥°å™¨
type TracedLogger struct {
    logger *Logger
    tracer trace.Tracer
}

func NewTracedLogger(logger *Logger, tracer trace.Tracer) *TracedLogger {
    return &TracedLogger{
        logger: logger,
        tracer: tracer,
    }
}

func (tl *TracedLogger) Info(ctx context.Context, msg string, fields ...zap.Field) {
    // æ·»åŠ spanäº‹ä»¶
    span := trace.SpanFromContext(ctx)
    span.AddEvent(msg)
    
    // æ·»åŠ é“¾è·¯ä¿¡æ¯åˆ°æ—¥å¿—
    traceFields := extractTraceFields(ctx)
    allFields := append(fields, traceFields...)
    
    tl.logger.Info(msg, allFields...)
}

func (tl *TracedLogger) Error(ctx context.Context, msg string, err error, fields ...zap.Field) {
    // è®°å½•é”™è¯¯åˆ°span
    span := trace.SpanFromContext(ctx)
    span.RecordError(err)
    
    // æ·»åŠ é“¾è·¯ä¿¡æ¯åˆ°æ—¥å¿—
    traceFields := extractTraceFields(ctx)
    allFields := append(fields, traceFields...)
    
    tl.logger.Error(msg, err, allFields...)
}

// è‡ªåŠ¨å…³è”ä¸šåŠ¡æ“ä½œå’Œæ—¥å¿—
func (tl *TracedLogger) WithOperation(ctx context.Context, operation string) (context.Context, func()) {
    ctx, span := tl.tracer.Start(ctx, operation)
    
    // è®°å½•æ“ä½œå¼€å§‹
    tl.Info(ctx, "Operation started", zap.String("operation", operation))
    
    return ctx, func() {
        defer span.End()
        tl.Info(ctx, "Operation completed", zap.String("operation", operation))
    }
}
```
:::

---

## ğŸ”§ æ—¥å¿—ç³»ç»Ÿå·¥ç¨‹å®è·µ

### å¤šç¯å¢ƒæ—¥å¿—é…ç½®

::: details ç¯å¢ƒé€‚é…çš„æ—¥å¿—é…ç½®
```go
package config

import (
    "os"
    "strings"
)

// ä¸åŒç¯å¢ƒçš„æ—¥å¿—é…ç½®
func GetLogConfig() LogConfig {
    env := strings.ToLower(os.Getenv("ENV"))
    
    switch env {
    case "development":
        return LogConfig{
            Level:      "debug",
            Encoding:   "console", // å¼€å‘ç¯å¢ƒä½¿ç”¨å¯è¯»æ€§å¥½çš„æ ¼å¼
            OutputPath: "stdout",
            MaxSize:    10,
            MaxBackups: 3,
            MaxAge:     7,
            Compress:   false,
        }
        
    case "testing":
        return LogConfig{
            Level:      "info",
            Encoding:   "json",
            OutputPath: "/var/log/app/test.log",
            MaxSize:    50,
            MaxBackups: 5,
            MaxAge:     14,
            Compress:   true,
        }
        
    case "staging":
        return LogConfig{
            Level:      "info",
            Encoding:   "json",
            OutputPath: "/var/log/app/staging.log",
            MaxSize:    100,
            MaxBackups: 10,
            MaxAge:     30,
            Compress:   true,
        }
        
    case "production":
        return LogConfig{
            Level:      "warn", // ç”Ÿäº§ç¯å¢ƒå‡å°‘æ—¥å¿—é‡
            Encoding:   "json",
            OutputPath: "/var/log/app/production.log",
            MaxSize:    500,
            MaxBackups: 20,
            MaxAge:     90,
            Compress:   true,
        }
        
    default:
        return LogConfig{
            Level:      "info",
            Encoding:   "json",
            OutputPath: "stdout",
            MaxSize:    10,
            MaxBackups: 3,
            MaxAge:     7,
            Compress:   false,
        }
    }
}

// æ•æ„Ÿä¿¡æ¯è„±æ•é…ç½®
type SanitizeConfig struct {
    FieldsToMask []string
    MaskPattern  string
}

func (sc *SanitizeConfig) SanitizeFields(fields map[string]interface{}) {
    for _, field := range sc.FieldsToMask {
        if _, exists := fields[field]; exists {
            fields[field] = sc.MaskPattern
        }
    }
}

var DefaultSanitizeConfig = SanitizeConfig{
    FieldsToMask: []string{
        "password", "token", "secret", "key", "credit_card",
        "ssn", "phone", "email", // æ ¹æ®GDPRç­‰è§„å®š
    },
    MaskPattern: "***MASKED***",
}
```
:::

### æ—¥å¿—èšåˆä¸ç›‘æ§

::: details ELK Stacké›†æˆå’Œå‘Šè­¦é…ç½®
```go
package monitoring

import (
    "bytes"
    "encoding/json"
    "net/http"
    "time"
    
    "go.uber.org/zap"
)

// Elasticsearchæ—¥å¿—è¾“å‡ºå™¨
type ElasticsearchWriter struct {
    endpoint string
    index    string
    client   *http.Client
    buffer   chan LogEntry
}

type LogEntry struct {
    Timestamp time.Time              `json:"@timestamp"`
    Level     string                 `json:"level"`
    Message   string                 `json:"message"`
    Service   string                 `json:"service"`
    Fields    map[string]interface{} `json:"fields"`
}

func NewElasticsearchWriter(endpoint, index string) *ElasticsearchWriter {
    ew := &ElasticsearchWriter{
        endpoint: endpoint,
        index:    index,
        client:   &http.Client{Timeout: 5 * time.Second},
        buffer:   make(chan LogEntry, 1000),
    }
    
    // å¯åŠ¨æ‰¹é‡å‘é€goroutine
    go ew.batchSender()
    
    return ew
}

func (ew *ElasticsearchWriter) Write(p []byte) (n int, err error) {
    var entry LogEntry
    if err := json.Unmarshal(p, &entry); err != nil {
        return 0, err
    }
    
    // æ·»åŠ æœåŠ¡ä¿¡æ¯
    entry.Service = os.Getenv("SERVICE_NAME")
    if entry.Service == "" {
        entry.Service = "unknown"
    }
    
    // éé˜»å¡å†™å…¥ç¼“å†²åŒº
    select {
    case ew.buffer <- entry:
        return len(p), nil
    default:
        // ç¼“å†²åŒºæ»¡ï¼Œä¸¢å¼ƒæ—¥å¿—é¿å…é˜»å¡
        return len(p), nil
    }
}

func (ew *ElasticsearchWriter) batchSender() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()
    
    var batch []LogEntry
    
    for {
        select {
        case entry := <-ew.buffer:
            batch = append(batch, entry)
            
            // æ‰¹æ¬¡å¤§å°è¾¾åˆ°é˜ˆå€¼ï¼Œç«‹å³å‘é€
            if len(batch) >= 100 {
                ew.sendBatch(batch)
                batch = batch[:0]
            }
            
        case <-ticker.C:
            // å®šæ—¶å‘é€
            if len(batch) > 0 {
                ew.sendBatch(batch)
                batch = batch[:0]
            }
        }
    }
}

func (ew *ElasticsearchWriter) sendBatch(batch []LogEntry) {
    if len(batch) == 0 {
        return
    }
    
    // æ„é€ æ‰¹é‡æ’å…¥è¯·æ±‚
    var buf bytes.Buffer
    for _, entry := range batch {
        // ç´¢å¼•å…ƒæ•°æ®
        indexMeta := map[string]interface{}{
            "index": map[string]interface{}{
                "_index": ew.index + "-" + entry.Timestamp.Format("2006.01.02"),
            },
        }
        
        metaBytes, _ := json.Marshal(indexMeta)
        buf.Write(metaBytes)
        buf.WriteByte('\n')
        
        // æ–‡æ¡£æ•°æ®
        docBytes, _ := json.Marshal(entry)
        buf.Write(docBytes)
        buf.WriteByte('\n')
    }
    
    // å‘é€è¯·æ±‚
    resp, err := ew.client.Post(
        ew.endpoint+"/_bulk",
        "application/x-ndjson",
        &buf,
    )
    
    if err != nil {
        // è®°å½•å‘é€å¤±è´¥ï¼Œä½†ä¸èƒ½ä½¿ç”¨æ—¥å¿—åº“ï¼ˆé¿å…å¾ªç¯ï¼‰
        return
    }
    defer resp.Body.Close()
}

// å‘Šè­¦è§„åˆ™é…ç½®
type AlertRule struct {
    Name        string
    Query       string
    Threshold   int
    Window      time.Duration
    Webhook     string
}

var CriticalAlerts = []AlertRule{
    {
        Name:      "Error Rate Too High",
        Query:     `level:error AND service:user-service`,
        Threshold: 10, // 5åˆ†é’Ÿå†…è¶…è¿‡10ä¸ªé”™è¯¯
        Window:    5 * time.Minute,
        Webhook:   "https://hooks.slack.com/services/xxx",
    },
    {
        Name:      "Database Connection Failed",
        Query:     `message:"database connection failed"`,
        Threshold: 1, // ç«‹å³å‘Šè­¦
        Window:    1 * time.Minute,
        Webhook:   "https://hooks.slack.com/services/xxx",
    },
    {
        Name:      "Memory Usage High",
        Query:     `fields.memory_usage:>0.8`,
        Threshold: 5, // è¿ç»­5æ¬¡å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%
        Window:    5 * time.Minute,
        Webhook:   "https://hooks.slack.com/services/xxx",
    },
}

// æ—¥å¿—æŒ‡æ ‡æ”¶é›†
type LogMetrics struct {
    logCount     map[string]int64
    errorCount   map[string]int64
    lastLogTime  time.Time
}

func (lm *LogMetrics) RecordLog(level, service string) {
    lm.logCount[level+":"+service]++
    lm.lastLogTime = time.Now()
    
    if level == "error" {
        lm.errorCount[service]++
    }
}

func (lm *LogMetrics) GetMetrics() map[string]interface{} {
    return map[string]interface{}{
        "log_count":     lm.logCount,
        "error_count":   lm.errorCount,
        "last_log_time": lm.lastLogTime,
    }
}
```
:::

### ç»“æ„åŒ–æ—¥å¿—æ ‡å‡†

::: details ä¼ä¸šçº§æ—¥å¿—å­—æ®µæ ‡å‡†
```go
package standards

import (
    "time"
    "go.uber.org/zap"
)

// æ ‡å‡†æ—¥å¿—å­—æ®µ
type StandardFields struct {
    // ç³»ç»Ÿå­—æ®µ
    Timestamp   time.Time `json:"@timestamp"`
    Level       string    `json:"level"`
    Message     string    `json:"message"`
    Service     string    `json:"service"`
    Version     string    `json:"version"`
    Environment string    `json:"environment"`
    
    // è¯·æ±‚å­—æ®µ
    TraceID   string `json:"trace_id,omitempty"`
    SpanID    string `json:"span_id,omitempty"`
    RequestID string `json:"request_id,omitempty"`
    UserID    string `json:"user_id,omitempty"`
    SessionID string `json:"session_id,omitempty"`
    
    // HTTPå­—æ®µ
    HTTPMethod     string `json:"http_method,omitempty"`
    HTTPPath       string `json:"http_path,omitempty"`
    HTTPStatusCode int    `json:"http_status_code,omitempty"`
    HTTPDuration   int64  `json:"http_duration_ms,omitempty"`
    
    // ä¸šåŠ¡å­—æ®µ
    Operation string                 `json:"operation,omitempty"`
    Entity    string                 `json:"entity,omitempty"`
    EntityID  string                 `json:"entity_id,omitempty"`
    Action    string                 `json:"action,omitempty"`
    Result    string                 `json:"result,omitempty"`
    
    // æŠ€æœ¯å­—æ®µ
    Component string `json:"component,omitempty"`
    Function  string `json:"function,omitempty"`
    Error     string `json:"error,omitempty"`
    Stack     string `json:"stack,omitempty"`
    
    // æ€§èƒ½å­—æ®µ
    CPUUsage    float64 `json:"cpu_usage,omitempty"`
    MemoryUsage int64   `json:"memory_usage,omitempty"`
    Latency     int64   `json:"latency_ms,omitempty"`
    
    // è‡ªå®šä¹‰å­—æ®µ
    Custom map[string]interface{} `json:"custom,omitempty"`
}

// æ—¥å¿—æ„å»ºå™¨
type LogBuilder struct {
    fields StandardFields
}

func NewLogBuilder() *LogBuilder {
    return &LogBuilder{
        fields: StandardFields{
            Timestamp:   time.Now(),
            Service:     os.Getenv("SERVICE_NAME"),
            Version:     os.Getenv("SERVICE_VERSION"),
            Environment: os.Getenv("ENVIRONMENT"),
            Custom:      make(map[string]interface{}),
        },
    }
}

func (lb *LogBuilder) WithTrace(traceID, spanID string) *LogBuilder {
    lb.fields.TraceID = traceID
    lb.fields.SpanID = spanID
    return lb
}

func (lb *LogBuilder) WithRequest(requestID, userID string) *LogBuilder {
    lb.fields.RequestID = requestID
    lb.fields.UserID = userID
    return lb
}

func (lb *LogBuilder) WithHTTP(method, path string, statusCode int, duration time.Duration) *LogBuilder {
    lb.fields.HTTPMethod = method
    lb.fields.HTTPPath = path
    lb.fields.HTTPStatusCode = statusCode
    lb.fields.HTTPDuration = duration.Nanoseconds() / 1e6 // è½¬æ¢ä¸ºæ¯«ç§’
    return lb
}

func (lb *LogBuilder) WithBusiness(operation, entity, entityID, action, result string) *LogBuilder {
    lb.fields.Operation = operation
    lb.fields.Entity = entity
    lb.fields.EntityID = entityID
    lb.fields.Action = action
    lb.fields.Result = result
    return lb
}

func (lb *LogBuilder) WithError(err error, stack string) *LogBuilder {
    if err != nil {
        lb.fields.Error = err.Error()
    }
    lb.fields.Stack = stack
    return lb
}

func (lb *LogBuilder) WithCustom(key string, value interface{}) *LogBuilder {
    lb.fields.Custom[key] = value
    return lb
}

func (lb *LogBuilder) ToZapFields() []zap.Field {
    fields := []zap.Field{
        zap.Time("@timestamp", lb.fields.Timestamp),
        zap.String("service", lb.fields.Service),
        zap.String("version", lb.fields.Version),
        zap.String("environment", lb.fields.Environment),
    }
    
    if lb.fields.TraceID != "" {
        fields = append(fields, zap.String("trace_id", lb.fields.TraceID))
    }
    if lb.fields.SpanID != "" {
        fields = append(fields, zap.String("span_id", lb.fields.SpanID))
    }
    if lb.fields.RequestID != "" {
        fields = append(fields, zap.String("request_id", lb.fields.RequestID))
    }
    if lb.fields.UserID != "" {
        fields = append(fields, zap.String("user_id", lb.fields.UserID))
    }
    
    // HTTPå­—æ®µ
    if lb.fields.HTTPMethod != "" {
        fields = append(fields,
            zap.String("http_method", lb.fields.HTTPMethod),
            zap.String("http_path", lb.fields.HTTPPath),
            zap.Int("http_status_code", lb.fields.HTTPStatusCode),
            zap.Int64("http_duration_ms", lb.fields.HTTPDuration),
        )
    }
    
    // ä¸šåŠ¡å­—æ®µ
    if lb.fields.Operation != "" {
        fields = append(fields,
            zap.String("operation", lb.fields.Operation),
            zap.String("entity", lb.fields.Entity),
            zap.String("entity_id", lb.fields.EntityID),
            zap.String("action", lb.fields.Action),
            zap.String("result", lb.fields.Result),
        )
    }
    
    // é”™è¯¯å­—æ®µ
    if lb.fields.Error != "" {
        fields = append(fields, zap.String("error", lb.fields.Error))
    }
    if lb.fields.Stack != "" {
        fields = append(fields, zap.String("stack", lb.fields.Stack))
    }
    
    // è‡ªå®šä¹‰å­—æ®µ
    for k, v := range lb.fields.Custom {
        fields = append(fields, zap.Any(k, v))
    }
    
    return fields
}

// ä½¿ç”¨ç¤ºä¾‹
func LogUserLogin(logger *Logger, userID, requestID string, success bool, duration time.Duration) {
    result := "success"
    if !success {
        result = "failure"
    }
    
    fields := NewLogBuilder().
        WithRequest(requestID, userID).
        WithBusiness("authentication", "user", userID, "login", result).
        WithCustom("login_duration_ms", duration.Nanoseconds()/1e6).
        ToZapFields()
    
    if success {
        logger.Info("User login successful", fields...)
    } else {
        logger.Warn("User login failed", fields...)
    }
}
```
:::

---

## ğŸ“‹ æ—¥å¿—æ²»ç†æ£€æŸ¥æ¸…å•

### ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼š
- [ ] ä½¿ç”¨å¼‚æ­¥æ—¥å¿—å†™å…¥
- [ ] åˆç†è®¾ç½®æ—¥å¿—çº§åˆ«ï¼ˆç”Ÿäº§ç¯å¢ƒwarn+ï¼‰
- [ ] é¿å…åœ¨çƒ­è·¯å¾„ä½¿ç”¨æ ¼å¼åŒ–æ—¥å¿—
- [ ] å®ç°æ—¥å¿—é‡‡æ ·ï¼ˆé«˜é¢‘æ—¥å¿—ï¼‰
- [ ] ç›‘æ§æ—¥å¿—å†™å…¥æ€§èƒ½

âœ… **å­˜å‚¨ç®¡ç†**ï¼š
- [ ] é…ç½®æ—¥å¿—è½®è½¬å’Œå‹ç¼©
- [ ] è®¾ç½®åˆç†çš„ä¿ç•™ç­–ç•¥
- [ ] ç›‘æ§ç£ç›˜ä½¿ç”¨ç‡
- [ ] å®ç°æ—¥å¿—å½’æ¡£ç­–ç•¥
- [ ] å»ºç«‹æ—¥å¿—æ¸…ç†æœºåˆ¶

âœ… **å®‰å…¨åˆè§„**ï¼š
- [ ] æ•æ„Ÿæ•°æ®è„±æ•å¤„ç†
- [ ] æ—¥å¿—è®¿é—®æƒé™æ§åˆ¶
- [ ] å®¡è®¡æ—¥å¿—å®Œæ•´æ€§
- [ ] ç¬¦åˆGDPRç­‰æ³•è§„è¦æ±‚
- [ ] æ—¥å¿—ä¼ è¾“åŠ å¯†

âœ… **ç›‘æ§å‘Šè­¦**ï¼š
- [ ] é”™è¯¯ç‡é˜ˆå€¼å‘Šè­¦
- [ ] å…³é”®ä¸šåŠ¡äº‹ä»¶ç›‘æ§
- [ ] æ—¥å¿—ç¼ºå¤±å‘Šè­¦
- [ ] æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- [ ] é“¾è·¯è¿½è¸ªé›†æˆ

### æ—¥å¿—è´¨é‡è¯„ä¼°æŒ‡æ ‡

::: details æ—¥å¿—è´¨é‡ç›‘æ§ç³»ç»Ÿ
```go
package quality

import (
    "regexp"
    "strings"
    "time"
)

type LogQualityMetrics struct {
    TotalLogs        int64
    StructuredLogs   int64
    ErrorLogs        int64
    SlowOperations   int64
    MissingTraceID   int64
    SensitiveDataLeaks int64
}

type LogQualityAnalyzer struct {
    sensitivePatterns []*regexp.Regexp
    requiredFields    []string
}

func NewLogQualityAnalyzer() *LogQualityAnalyzer {
    // æ•æ„Ÿæ•°æ®æ£€æµ‹æ¨¡å¼
    patterns := []*regexp.Regexp{
        regexp.MustCompile(`\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b`), // ä¿¡ç”¨å¡å·
        regexp.MustCompile(`\b\d{3}-\d{2}-\d{4}\b`),                       // ç¤¾ä¼šå®‰å…¨å·
        regexp.MustCompile(`\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b`), // é‚®ç®±
        regexp.MustCompile(`password["\s]*[:=]["\s]*[^"\s]+`),             // å¯†ç 
    }
    
    return &LogQualityAnalyzer{
        sensitivePatterns: patterns,
        requiredFields: []string{"timestamp", "level", "service", "trace_id"},
    }
}

func (lqa *LogQualityAnalyzer) AnalyzeLog(logEntry map[string]interface{}) LogQualityIssues {
    var issues LogQualityIssues
    
    // æ£€æŸ¥å¿…éœ€å­—æ®µ
    for _, field := range lqa.requiredFields {
        if _, exists := logEntry[field]; !exists {
            issues.MissingFields = append(issues.MissingFields, field)
        }
    }
    
    // æ£€æŸ¥æ•æ„Ÿæ•°æ®æ³„éœ²
    if message, exists := logEntry["message"].(string); exists {
        for _, pattern := range lqa.sensitivePatterns {
            if pattern.MatchString(message) {
                issues.SensitiveDataFound = true
                break
            }
        }
    }
    
    // æ£€æŸ¥é”™è¯¯æ—¥å¿—æ˜¯å¦åŒ…å«stack trace
    if level, exists := logEntry["level"].(string); exists && level == "error" {
        if _, hasStack := logEntry["stack"]; !hasStack {
            issues.ErrorWithoutStack = true
        }
    }
    
    return issues
}

type LogQualityIssues struct {
    MissingFields      []string
    SensitiveDataFound bool
    ErrorWithoutStack  bool
}

// æ—¥å¿—è´¨é‡æŠ¥å‘Š
func GenerateQualityReport(logs []map[string]interface{}) QualityReport {
    analyzer := NewLogQualityAnalyzer()
    report := QualityReport{
        TotalLogs: len(logs),
        Timestamp: time.Now(),
    }
    
    for _, log := range logs {
        issues := analyzer.AnalyzeLog(log)
        
        if len(issues.MissingFields) > 0 {
            report.MissingFieldsCount++
        }
        if issues.SensitiveDataFound {
            report.SensitiveDataCount++
        }
        if issues.ErrorWithoutStack {
            report.ErrorsWithoutStackCount++
        }
    }
    
    // è®¡ç®—è´¨é‡åˆ†æ•°
    report.QualityScore = float64(report.TotalLogs-report.MissingFieldsCount-report.SensitiveDataCount) / float64(report.TotalLogs) * 100
    
    return report
}

type QualityReport struct {
    TotalLogs               int
    MissingFieldsCount      int
    SensitiveDataCount      int
    ErrorsWithoutStackCount int
    QualityScore           float64
    Timestamp              time.Time
}
```
:::

---

## ğŸ¯ æ—¥å¿—åº“é€‰æ‹©æŒ‡å—

### é€‰æ‹©å†³ç­–çŸ©é˜µ

```
æ—¥å¿—åº“é€‰æ‹©æŒ‡å—
â”œâ”€â”€ æ€§èƒ½è¦æ±‚æé«˜ï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ Zapï¼ˆé‡‘èã€æ¸¸æˆåœºæ™¯ï¼‰
â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­è¯„ä¼°
â”œâ”€â”€ éœ€è¦ä¸°å¯Œçš„HookåŠŸèƒ½ï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ Logrusï¼ˆå¤æ‚ä¸šåŠ¡é€»è¾‘ï¼‰
â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­è¯„ä¼°
â”œâ”€â”€ è¿½æ±‚æç®€è®¾è®¡ï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ Zerologï¼ˆå¾®æœåŠ¡ã€å®¹å™¨åŒ–ï¼‰
â”‚   â””â”€â”€ å¦ â†’ æ ‡å‡†åº“log
```

**æœ€ç»ˆå»ºè®®**ï¼š

- **é«˜æ€§èƒ½åœºæ™¯**ï¼šé€‰æ‹©**Zap**ï¼Œé…åˆåˆç†çš„é…ç½®å’Œæœ€ä½³å®è·µ
- **åŠŸèƒ½ä¸°å¯Œåœºæ™¯**ï¼šé€‰æ‹©**Logrus**ï¼Œåˆ©ç”¨å…¶ä¸°å¯Œçš„Hookç”Ÿæ€
- **ç®€å•åœºæ™¯**ï¼šé€‰æ‹©**Zerolog**ï¼Œä»£ç ç®€æ´ï¼Œæ€§èƒ½è‰¯å¥½
- **å­¦ä¹ æˆæœ¬æ•æ„Ÿ**ï¼šä»**æ ‡å‡†åº“log**å¼€å§‹ï¼Œé€æ­¥å‡çº§

è®°ä½ï¼š**æ—¥å¿—ç³»ç»Ÿçš„ä»·å€¼ä¸åœ¨äºè®°å½•äº†å¤šå°‘ä¿¡æ¯ï¼Œè€Œåœ¨äºåœ¨å…³é”®æ—¶åˆ»èƒ½å¤Ÿå¿«é€Ÿå®šä½é—®é¢˜ã€‚** å»ºç«‹å®Œå–„çš„æ—¥å¿—è§„èŒƒå’Œæ²»ç†ä½“ç³»ï¼Œæ¯”é€‰æ‹©æœ€æ–°çš„æ—¥å¿—åº“æ›´é‡è¦ã€‚
